{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First Steps\n",
    "\n",
    "### 0.1. Impotring libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.datasets import fetch_datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    CondensedNearestNeighbour,\n",
    "    TomekLinks,\n",
    "    OneSidedSelection,\n",
    "    EditedNearestNeighbours,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    AllKNN,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    NearMiss,\n",
    "    InstanceHardnessThreshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../kdd2004.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Imbalanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced target\n",
    "data.target.value_counts() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Separate train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),  # drop the target\n",
    "    data['target'],  # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Undersampling\n",
    "\n",
    "__Method of data Exclusion__: Random <br>\n",
    "__Final Dataset Size__: 2 x minority class <br>\n",
    "__Fixed vs Cleaning__: Fixed <br>\n",
    "__Under-sampling criteria__: Random <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy='auto',  # samples only from majority class\n",
    "    random_state=0, \n",
    "    replacement=True\n",
    ")  \n",
    "\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of undersampled data\n",
    "\n",
    "X_rus.shape, y_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of positive class in original dataset\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original ds\n",
    "\n",
    "sns.scatterplot(data=data.sample(1784, random_state=0),\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for undersample ds\n",
    "\n",
    "col_names = [str(i) for i in range(74)] + ['target']\n",
    "\n",
    "data_resampled = pd.concat([X_rus, y_rus], axis=1)\n",
    "data_resampled.columns = col_names\n",
    "\n",
    "sns.scatterplot(data=data_resampled, x=\"0\", y=\"1\", hue=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are similar to that of the original data. The reason more purple dots are seen, is because now they are not covered by the pink ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Condensed Nearest Neighbours\n",
    "\n",
    "__Method of data Exclusion__: Samples outside the boundary between the classes <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Keep boundary observations <br>\n",
    "\n",
    "#### Resempling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this might take a while\n",
    "\n",
    "cnn = CondensedNearestNeighbour(\n",
    "    sampling_strategy='auto', \n",
    "    random_state=0,\n",
    "    n_neighbors=1,\n",
    "    n_jobs=4) \n",
    "\n",
    "X_cnn, y_cnn = cnn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of undersampled data\n",
    "\n",
    "X_cnn.shape, y_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of positive class in original dataset\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_cnn,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_resampled)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_cnn,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_cnn)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tomek Links\n",
    "\n",
    "__Method of data Exclusion__: removes samples which are Tomek Links <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Remove noisy observations <br>\n",
    "\n",
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Tomek Links\n",
    "\n",
    "tl = TomekLinks(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    n_jobs=4)  # I have 4 cores in my laptop\n",
    "\n",
    "X_tl, y_tl = tl.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of undersampled data\n",
    "\n",
    "X_tl.shape, y_tl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The under-sampled data set is very similar to the original dataset, only 5 observations were removed. So there is no real point in testing the performance. The difference in performance will most likely be driven by the randomness of Random Forests than by the difference in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of positive class in original dataset\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_tl,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_tl)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_tl,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_tl)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One Sided Selection\n",
    "\n",
    "__Method of data Exclusion__: CNN + Tomek Links <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Both keep and remove boundary observations <br>\n",
    "\n",
    "#### Resempling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is going to take a while\n",
    "\n",
    "oss = OneSidedSelection(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    random_state=0,\n",
    "    n_neighbors=1,\n",
    "    n_jobs=4) \n",
    "\n",
    "X_oss, y_oss = oss.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of undersampled data\n",
    "X_oss.shape, y_oss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of positive class in original dataset\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_oss,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_oss)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_oss,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_oss)\n",
    "\n",
    "plt.title('Undersampled data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edited Nearest Neighbours\n",
    "\n",
    "__Method of data Exclusion__: Observation's class is different from that of its nearest neighbours <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Remove noisy observations <br>\n",
    "\n",
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edited nearest neighbours\n",
    "\n",
    "enn = EditedNearestNeighbours(\n",
    "    sampling_strategy='auto',  # resamples the majority class\n",
    "    n_neighbors=3,\n",
    "    kind_sel='all', \n",
    "    n_jobs=4)\n",
    "\n",
    "X_enn, y_enn = enn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare shapes\n",
    "\n",
    "X_train.shape, X_enn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enn undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_enn,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_enn)\n",
    "\n",
    "plt.title('Edited NN data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data, other set of variables\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# enn undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_enn,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_enn)\n",
    "\n",
    "plt.title('Edited NN data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Repeated Edited Nearest Neighbours\n",
    "\n",
    "__Method of data Exclusion__: Repeats ENN multiple times <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Remove noisy observations <br>\n",
    "\n",
    "\n",
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated NN\n",
    "\n",
    "renn = RepeatedEditedNearestNeighbours(\n",
    "    sampling_strategy='auto',\n",
    "    n_neighbors=3,\n",
    "    kind_sel='all',\n",
    "    n_jobs=4,\n",
    "    max_iter=100)\n",
    "\n",
    "X_renn, y_renn = renn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare shapes\n",
    "\n",
    "X_train.shape, X_renn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renn undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_renn,\n",
    "                x=\"0\",\n",
    "                y=\"1\",\n",
    "                hue=y_renn)\n",
    "\n",
    "plt.title('Repeated Edited NN data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data, other set of variables\n",
    "\n",
    "sns.scatterplot(data=X_train,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_train)\n",
    "\n",
    "plt.title('Original data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# renn undersampled data\n",
    "\n",
    "sns.scatterplot(data=X_renn,\n",
    "                x=\"4\",\n",
    "                y=\"5\",\n",
    "                hue=y_renn)\n",
    "\n",
    "plt.title('Repeated Edited NN data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. All KNN\n",
    "\n",
    "__Method of data Exclusion__: Repeats ENN, plus 1 neighbour in each KNN iteration <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Remove noisy observations <br>\n",
    "\n",
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edited nearest neighbours\n",
    "\n",
    "allknn = AllKNN(\n",
    "    sampling_strategy='auto',\n",
    "    n_neighbors=3,\n",
    "    kind_sel='all',\n",
    "    n_jobs=4,\n",
    ")  # I hve 4 cores in my laptop\n",
    "\n",
    "X_allknn, y_allknn = allknn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare shapes\n",
    "\n",
    "X_train.shape, X_enn.shape, X_renn.shape, X_allknn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Neighbourhood Cleaning Rule\n",
    "\n",
    "__Method of data Exclusion__: Combines ENN with a 1 KNN data exclusion criteria <br>\n",
    "__Final Dataset Size__: Varies <br>\n",
    "__Fixed vs Cleaning__: Cleaning <br>\n",
    "__Under-sampling criteria__: Remove noisy observations <br>\n",
    "\n",
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Neighbourhood cleaning rule\n",
    "\n",
    "ncr = NeighbourhoodCleaningRule(\n",
    "    sampling_strategy='auto',# removes only the majority class\n",
    "    n_neighbors=3, # 3 KNN\n",
    "    kind_sel='all', # all neighbouring observations should show the same class\n",
    "    n_jobs=4, # 4 processors in my laptop\n",
    "    threshold_cleaning=0.5) # threshold no exclude or not observations \n",
    "\n",
    "X_ncr, y_ncr = ncr.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare shapes\n",
    "\n",
    "X_train.shape, X_ncr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the rule did not exclude a lot of samples, only 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. NearMiss\n",
    "\n",
    "__Final Dataset Size__: 2 x minority class <br>\n",
    "__Fixed vs Cleaning__: Fixed <br>\n",
    "__Under-sampling criteria__: Keep boundary observations <br>\n",
    "\n",
    "#### Resempling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearMiss version 1\n",
    "\n",
    "nm1 = NearMiss(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    version=1,\n",
    "    n_neighbors=3,\n",
    "    n_jobs=4)  # I have 4 cores in my laptop\n",
    "\n",
    "X_nm1, y_nm1 = nm1.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearMiss version 2\n",
    "\n",
    "nm2 = NearMiss(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    version=2,\n",
    "    n_neighbors=3,\n",
    "    n_jobs=4)  # I have 4 cores in my laptop\n",
    "\n",
    "X_nm2, y_nm2 = nm2.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearMiss version 3\n",
    "\n",
    "nm3 = NearMiss(\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    version=3,\n",
    "    n_neighbors=3,\n",
    "    n_jobs=4)  # I have 4 cores in my laptop\n",
    "\n",
    "X_nm3, y_nm3 = nm3.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare shapes\n",
    "\n",
    "X_train.shape, X_nm1.shape, X_nm2.shape, X_nm3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Instance Hardness Threshold\n",
    "\n",
    "__Method of data Exclusion__: Probability by a certain classifier\n",
    "is above a threshold <br>\n",
    "__Final Dataset Size__: Varies. Minimum 2 x minority class <br>\n",
    "__Fixed vs Cleaning__: Fixed <br>\n",
    "__Under-sampling criteria__: Remove noisy observations <br>\n",
    "\n",
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance hardness threshold using logistic regression\n",
    "\n",
    "iht_logit = InstanceHardnessThreshold(\n",
    "    estimator=LogisticRegression(random_state=0),\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    random_state=0,\n",
    "    n_jobs=4, \n",
    "    cv=3)  # not 5 as this is only a demo work\n",
    "\n",
    "X_logit, y_logit = iht_logit.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance hardness threshold using random forests\n",
    "\n",
    "iht_rf = InstanceHardnessThreshold(\n",
    "    estimator=RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "    sampling_strategy='auto',  # undersamples only the majority class\n",
    "    random_state=0,\n",
    "    n_jobs=4, # have 4 processors in my laptop\n",
    "    cv=3)\n",
    "\n",
    "\n",
    "X_rf, y_rf = iht_rf.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare shapes\n",
    "\n",
    "X_train.shape, X_logit.shape, X_rf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning performance comparison\n",
    "\n",
    "Here, I will try to compare Random Fores and Logistic Regression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_scaling(X_train, X_test=None):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test,\n",
    "                     X_resampled, y_resampled):\n",
    "    \n",
    "    print(\"RANDOM FOREST\", \"\\n\")\n",
    "    \n",
    "    # for original sets\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Original Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Original Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # for resampled sets\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    print('Resampled Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Resampled Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    print(\"*\"*60)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logisticRegression(X_train, X_test, y_train, y_test,\n",
    "                     X_resampled, y_resampled):\n",
    "    \n",
    "    print(\"LOGISTIC REGRESION\", \"\\n\")\n",
    "    \n",
    "    # for original dsets\n",
    "    do_scaling(X_train, X_test)    \n",
    "    \n",
    "    logr = LogisticRegression(random_state=0)\n",
    "    logr.fit(X_train, y_train)\n",
    "\n",
    "    print('Original Train set')\n",
    "    pred = logr.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Original Test set')\n",
    "    pred = logr.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # for resampled dsets\n",
    "    do_scaling(X_resampled)\n",
    "    \n",
    "    logr = LogisticRegression(random_state=0)\n",
    "    logr.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    print('Resampled Train set')\n",
    "    pred = logr.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Resampled Test set')\n",
    "    pred = logr.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    print(\"*\"*60)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KNN(X_train, X_test, y_train, y_test,\n",
    "                     X_resampled, y_resampled):\n",
    "    \n",
    "    print(\"KNN\", \"\\n\")\n",
    "    \n",
    "    # for original dsets\n",
    "    #do_scaling(X_train, X_test)\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    print('Original rain set')\n",
    "    pred = knn.predict_proba(X_train)\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Original test set')\n",
    "    pred = knn.predict_proba(X_test)\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # for resampled dsets\n",
    "    #do_scaling(X_resampled)\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    print('Resampled Train set')\n",
    "    pred = knn.predict_proba(X_resampled)\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Resampled Test set')\n",
    "    pred = knn.predict_proba(X_test)\n",
    "    print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
    "    \n",
    "    print(\"*\"*60)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML_models(X_train, X_test, y_train, y_test, X_resampled, y_resampled):\n",
    "    run_randomForests(X_train, X_test, y_train, y_test, X_resampled, y_resampled)\n",
    "    run_logisticRegression(X_train, X_test, y_train, y_test, X_resampled, y_resampled)\n",
    "    #run_KNN(X_train, X_test, y_train, y_test, X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_ML_models(X_train, X_test, y_train, y_test, X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using imbalanced dataset\n",
    "\n",
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train,\n",
    "                  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using undersampled dataset\n",
    "\n",
    "run_randomForests(X_resampled,\n",
    "                  X_test,\n",
    "                  y_resampled,\n",
    "                  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a big jump in model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logisticRegression(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = LogisticRegression(random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
